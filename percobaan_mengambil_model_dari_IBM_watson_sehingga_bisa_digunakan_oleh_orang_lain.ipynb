{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQg7nCmwjePr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UOMMN_8hz7c",
        "outputId": "bfaf9970-2908-4e9a-ca3e-85f5b1d19e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring response\n",
            "{'predictions': [{'id': 'dense', 'fields': ['prediction', 'prediction_classes', 'probability'], 'values': [[[0.7859370112419128], [1], [0.7859370112419128]]]}]}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Your API key and token setup\n",
        "API_KEY = \"xwjt6zsCJ1lN54XQyEoS3LVFGgfpr9Iy0xqNEbahX6KY\"\n",
        "token_response = requests.post('https://iam.cloud.ibm.com/identity/token', data={\"apikey\":API_KEY, \"grant_type\": 'urn:ibm:params:oauth:grant-type:apikey'})\n",
        "mltoken = token_response.json()[\"access_token\"]\n",
        "\n",
        "# Header for the request\n",
        "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n",
        "\n",
        "# Example input text\n",
        "baru = [\"suami lo ganteng banget dah\"]\n",
        "\n",
        "# Tokenizer setup (assuming it's the same tokenizer used during training)\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "\n",
        "# Fit the tokenizer on your training data (replace df['text_processed'].values with your actual training data)\n",
        "# tokenizer.fit_on_texts(df['text_processed'].values)\n",
        "\n",
        "# For demonstration purposes, we will fit the tokenizer on the example input text\n",
        "# In practice, you should fit on your entire training corpus\n",
        "tokenizer.fit_on_texts(baru)\n",
        "\n",
        "# Convert the input text to sequences\n",
        "input_sequence = tokenizer.texts_to_sequences(baru)\n",
        "\n",
        "# Pad the sequence to the required length (113 in this case)\n",
        "maxlen = 113\n",
        "input_sequence_padded = pad_sequences(input_sequence, maxlen=maxlen)\n",
        "\n",
        "# Ensure the input is in the correct shape (batch_size, maxlen)\n",
        "input_sequence_padded = input_sequence_padded.tolist()  # Convert to list for JSON serialization\n",
        "\n",
        "# Prepare the payload for scoring\n",
        "payload_scoring = {\"input_data\": [{\"values\": input_sequence_padded}]}\n",
        "\n",
        "# Make the request to the IBM model\n",
        "response_scoring = requests.post(\n",
        "    'https://us-south.ml.cloud.ibm.com/ml/v4/deployments/619264d5-8cdd-454b-b202-19615dc46323/predictions?version=2021-05-01',\n",
        "    json=payload_scoring,\n",
        "    headers={'Authorization': 'Bearer ' + mltoken}\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(\"Scoring response\")\n",
        "print(response_scoring.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Your API key and token setup\n",
        "API_KEY = \"xwjt6zsCJ1lN54XQyEoS3LVFGgfpr9Iy0xqNEbahX6KY\"\n",
        "token_response = requests.post('https://iam.cloud.ibm.com/identity/token', data={\"apikey\":API_KEY, \"grant_type\": 'urn:ibm:params:oauth:grant-type:apikey'})\n",
        "mltoken = token_response.json()[\"access_token\"]\n",
        "\n",
        "# Header for the request\n",
        "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n",
        "\n",
        "# Example input text\n",
        "baru = [\"suami ku ganteng\"]\n",
        "\n",
        "# Tokenizer setup (assuming it's the same tokenizer used during training)\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "\n",
        "# Fit the tokenizer on your training data (replace df['text_processed'].values with your actual training data)\n",
        "# tokenizer.fit_on_texts(df['text_processed'].values)\n",
        "\n",
        "# For demonstration purposes, we will fit the tokenizer on the example input text\n",
        "# In practice, you should fit on your entire training corpus\n",
        "tokenizer.fit_on_texts(baru)\n",
        "\n",
        "# Convert the input text to sequences\n",
        "input_sequence = tokenizer.texts_to_sequences(baru)\n",
        "\n",
        "# Pad the sequence to the required length (113 in this case)\n",
        "maxlen = 113\n",
        "input_sequence_padded = pad_sequences(input_sequence, maxlen=maxlen)\n",
        "\n",
        "# Ensure the input is in the correct shape (batch_size, maxlen)\n",
        "input_sequence_padded = input_sequence_padded.tolist()  # Convert to list for JSON serialization\n",
        "\n",
        "# Prepare the payload for scoring\n",
        "payload_scoring = {\"input_data\": [{\"values\": input_sequence_padded}]}\n",
        "\n",
        "# Make the request to the IBM model\n",
        "response_scoring = requests.post(\n",
        "    'https://us-south.ml.cloud.ibm.com/ml/v4/deployments/619264d5-8cdd-454b-b202-19615dc46323/predictions?version=2021-05-01',\n",
        "    json=payload_scoring,\n",
        "    headers={'Authorization': 'Bearer ' + mltoken}\n",
        ")\n",
        "\n",
        "# Process the response\n",
        "response_json = response_scoring.json()\n",
        "prediction_value = response_json['predictions'][0]['values'][0][0][0]\n",
        "\n",
        "# Determine if the statement is negative or positive\n",
        "if prediction_value >= 0.8:\n",
        "    sentiment = \"negative\"\n",
        "else:\n",
        "    sentiment = \"positive\"\n",
        "\n",
        "# Print the readable output\n",
        "print(f'The statement \"{baru[0]}\" is a {sentiment} statement with a prediction value of {prediction_value:.2f}.')\n"
      ],
      "metadata": {
        "id": "a_QqP1ZhjDpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0016f55d-984f-4a6c-cc22-d26e02d5194d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The statement \"suami ku ganteng\" is a negative statement with a prediction value of 0.81.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TC4FwgouX5ld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}